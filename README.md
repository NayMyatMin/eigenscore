# INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection (ICLR-2024)

<div align=center><img src="https://github.com/alibaba/eigenscore/blob/main/data/datasets/fig.png" width="750" /></div>


* This repository contains code for our paper **INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection** [Download paper here]([https://arxiv.org/abs/1912.11976](https://arxiv.org/pdf/2402.03744))
* If you have any question about our paper or code, please don't hesitate to contact with me chench@zju.edu.cn/ercong.cc@alibaba-inc.com, we will update our repository accordingly

## Setup
* **Dataset** The dataset can be downloaded here ...
* **Requirements** ...
